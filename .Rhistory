install.packages(c("stargazer", "latticeExtra", "readr"))
install.packages("nnet")
install.packages("kableExtra")
install.packages("tinytex")
unlink('C:/Users/Jose/Dropbox/Econ Ed Trends/EconEdPaper2_cache', recursive = TRUE)
# List of useful packages
pkg <- c("tidyr", "dplyr", "ggplot2", "knitr", "rmarkdown")
# Check if packages are not installed and assign the
# names of the uninstalled packages to the variable new.pkg
new.pkg <- pkg[!(pkg %in% installed.packages())]
# If there are any packages in the list that aren't installed,
# install them
if (length(new.pkg)) {
install.packages(new.pkg, repos = "http://cran.rstudio.com")
}
install.packages("citr")
library("citr", lib.loc="~/R/win-library/3.4")
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
install.packages("tm")
install.packages("SnowballC")
library("SnowballC", lib.loc="~/R/win-library/3.4")
wordStem(c("consumer","consumption"))
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
install.packages("lubridate")
citr:::insert_citation()
print("# Tables")
print("# Tables",quote = FALSE)
display("# Tables")
cat("# Tables")
library("SnowballC", lib.loc="~/R/win-library/3.4")
wordStem(c("econometrics","economy","economics"))
citr:::insert_citation()
citr:::insert_citation()
citr:::insert_citation()
install.packages("easypackages")
# This script describes gathering data from an API
# We will need three packages: httr, jsonlite, lubrdidate
# to ease the code I use easypackages
library(easypackages)
mypackages<-c("httr", "jsonlite", "lubridate")
packages(mypackages)
libraries(mypackages)
# This script describes gathering data from an API
# We will need three packages: httr, jsonlite, lubrdidate
# to ease the code I use easypackages
library(easypackages)
mypackages<-c("httr", "jsonlite", "lubridate")
packages(mypackages)
libraries(mypackages)
options(stringsAsFactors = FALSE)
# First let's access an open API
# Quandl Key u7mzU7dPxbrAm3_c3LEb
# Typical api format https://www.quandl.com/api/v3/datasets/WIKI/FB/data.csv?api_key=YOURAPIKEYHERE
#Quandl Codes
#To download a dataset, you will need to know its “Quandl code”.  In the above example, you downloaded a dataset with the Quandl code “WIKI/FB”.
#Every Quandl code has 2 parts: the database code (“WIKI”) which specifies where the data comes from, and the dataset code (“FB”) which identifies the specific time series you want.
#You can find Quandl codes on our website, using our data browser.
base<-"https://www.quandl.com/api/v3/datasets/"
dataname<-"WIKI/FB/data.csv?"
key <-"api_key=u7mzU7dPxbrAm3_c3LEb"
url <- paste(base,dataname,key, sep="")
# This script describes gathering data from an API
# We will need three packages: httr, jsonlite, lubrdidate
# to ease the code I use easypackages
library(easypackages)
mypackages<-c("httr", "jsonlite", "lubridate")
packages(mypackages)
libraries(mypackages)
options(stringsAsFactors = FALSE)
# First let's access an open API
# Quandl Key u7mzU7dPxbrAm3_c3LEb
# Typical api format https://www.quandl.com/api/v3/datasets/WIKI/FB/data.csv?api_key=YOURAPIKEYHERE
#Quandl Codes
#To download a dataset, you will need to know its “Quandl code”.  In the above example, you downloaded a dataset with the Quandl code “WIKI/FB”.
#Every Quandl code has 2 parts: the database code (“WIKI”) which specifies where the data comes from, and the dataset code (“FB”) which identifies the specific time series you want.
#You can find Quandl codes on our website, using our data browser.
base<-"https://www.quandl.com/api/v3/datasets/"
dataname<-"WIKI/FB/data.csv?"
key <-"api_key=u7mzU7dPxbrAm3_c3LEb"
url <- paste(base,dataname,key, sep="")
raw.result <- GET(url = url)
# This script describes gathering data from an API
# We will need three packages: httr, jsonlite, lubrdidate
# to ease the code I use easypackages
library(easypackages)
mypackages<-c("httr", "jsonlite", "lubridate")
packages(mypackages)
libraries(mypackages)
options(stringsAsFactors = FALSE)
# First let's access an open API
# Quandl Key u7mzU7dPxbrAm3_c3LEb
# Typical api format https://www.quandl.com/api/v3/datasets/WIKI/FB/data.csv?api_key=YOURAPIKEYHERE
#Quandl Codes
#To download a dataset, you will need to know its “Quandl code”.  In the above example, you downloaded a dataset with the Quandl code “WIKI/FB”.
#Every Quandl code has 2 parts: the database code (“WIKI”) which specifies where the data comes from, and the dataset code (“FB”) which identifies the specific time series you want.
#You can find Quandl codes on our website, using our data browser.
base<-"https://www.quandl.com/api/v3/datasets/"
dataname<-"WIKI/FB/data.csv?"
key <-"api_key=u7mzU7dPxbrAm3_c3LEb"
url <- paste(base,dataname,key, sep="")
raw.result <- GET(url = url)
names(raw.result)
head(raw.result$content)
raw.result$status_code
this.raw.content <- rawToChar(raw.result$content)
nchar(this.raw.content)
substr(this.raw.content, 1, 100)
this.content <- fromJSON(this.raw.content)
this.content <- fromCSV(this.raw.content)
this.raw.content
mydata <- read.table(this.raw.content, header=TRUE,
sep=",", row.names="id")
mydata <- read.table(this.raw.content, header=TRUE,
sep=",")
mydata <- read.csv(this.raw.content)
substr(this.raw.content, 1, 100)
substr(this.raw.content)
# This script describes gathering data from an API
# We will need three packages: httr, jsonlite, lubrdidate
# to ease the code I use easypackages
library(easypackages)
mypackages<-c("httr", "jsonlite", "lubridate")
packages(mypackages)
libraries(mypackages)
options(stringsAsFactors = FALSE)
# First let's access an open API
# Quandl Key u7mzU7dPxbrAm3_c3LEb
# Typical api format https://www.quandl.com/api/v3/datasets/WIKI/FB/data.csv?api_key=YOURAPIKEYHERE
#Quandl Codes
#To download a dataset, you will need to know its “Quandl code”.  In the above example, you downloaded a dataset with the Quandl code “WIKI/FB”.
#Every Quandl code has 2 parts: the database code (“WIKI”) which specifies where the data comes from, and the dataset code (“FB”) which identifies the specific time series you want.
#You can find Quandl codes on our website, using our data browser.
base<-"https://www.quandl.com/api/v3/datasets/"
dataname<-"WIKI/FB/data.csv?"
key <-"api_key=u7mzU7dPxbrAm3_c3LEb"
url <- paste(base,dataname,key, sep="")
raw.result <- GET(url = url)
names(raw.result)
raw.result$content
# This script describes gathering data from an API
# We will need three packages: httr, jsonlite, lubrdidate
# to ease the code I use easypackages
library(easypackages)
mypackages<-c("httr", "jsonlite", "lubridate")
packages(mypackages)
libraries(mypackages)
options(stringsAsFactors = FALSE)
# First let's access an open API
# Quandl Key u7mzU7dPxbrAm3_c3LEb
# Typical api format https://www.quandl.com/api/v3/datasets/WIKI/FB/data.csv?api_key=YOURAPIKEYHERE
#Quandl Codes
#To download a dataset, you will need to know its “Quandl code”.  In the above example, you downloaded a dataset with the Quandl code “WIKI/FB”.
#Every Quandl code has 2 parts: the database code (“WIKI”) which specifies where the data comes from, and the dataset code (“FB”) which identifies the specific time series you want.
#You can find Quandl codes on our website, using our data browser.
base<-"https://www.quandl.com/api/v3/datasets/"
dataname<-"WIKI/FB/data.csv?"
key <-"api_key=u7mzU7dPxbrAm3_c3LEb"
url <- paste(base,dataname,key, sep="")
raw.result <- GET(url = url)
names(raw.result)
this.raw.content <- rawToChar(raw.result$content)
read.table(this.raw.content)
as.data.frame(this.raw.content)
strsplit(this.raw.content, split="\n")
read.csv(strsplit(this.raw.content, split="\n"))
read.csv(strsplit(this.raw.content, split="\n"), header = TRUE)
r1<-character(strsplit(this.raw.content, split="\n")
)
r1<-unlist(strsplit(this.raw.content, split="\n"))
r1<-read.csv(unlist(strsplit(this.raw.content, split="\n")))
r1<-read.csv(unlist(strsplit(this.raw.content, split="\n")),header=TRUE)
head(r1,1,100)
r1
read.table(r1,sep=",", header=TRUE)
r1{1:100}
r1[1:100]
r1[1]
r2<-r[1]
r2<-r1[1]
r1<-[2:end]
r1<-r1[2:end]
r1<-r1[2:]
read.csv(r1,sep=",")
# This script describes gathering data from an API
# We will need three packages: httr, jsonlite, lubrdidate
# to ease the code I use easypackages
library(easypackages)
mypackages<-c("httr", "jsonlite", "lubridate")
packages(mypackages)
libraries(mypackages)
options(stringsAsFactors = FALSE)
# First let's access an open API
# Quandl Key u7mzU7dPxbrAm3_c3LEb
# Typical api format https://www.quandl.com/api/v3/datasets/WIKI/FB/data.csv?api_key=YOURAPIKEYHERE
#Quandl Codes
#To download a dataset, you will need to know its “Quandl code”.  In the above example, you downloaded a dataset with the Quandl code “WIKI/FB”.
#Every Quandl code has 2 parts: the database code (“WIKI”) which specifies where the data comes from, and the dataset code (“FB”) which identifies the specific time series you want.
#You can find Quandl codes on our website, using our data browser.
base<-"https://www.quandl.com/api/v3/datasets/"
dataname<-"WIKI/FB/data.csv?"
key <-"api_key=u7mzU7dPxbrAm3_c3LEb"
url <- paste(base,dataname,key, sep="")
raw.result <- GET(url = url)
m1<-read.csv(url)
View(m1)
# This script describes gathering data from an API
# We will need three packages: httr, jsonlite, lubrdidate
# to ease the code I use easypackages
library(easypackages)
mypackages<-c("httr", "jsonlite", "lubridate")
packages(mypackages)
libraries(mypackages)
options(stringsAsFactors = FALSE)
# First let's access an open API
# Quandl Key u7mzU7dPxbrAm3_c3LEb
# Typical api format https://www.quandl.com/api/v3/datasets/WIKI/FB/data.csv?api_key=YOURAPIKEYHERE
#Quandl Codes
#To download a dataset, you will need to know its “Quandl code”.  In the above example, you downloaded a dataset with the Quandl code “WIKI/FB”.
#Every Quandl code has 2 parts: the database code (“WIKI”) which specifies where the data comes from, and the dataset code (“FB”) which identifies the specific time series you want.
#You can find Quandl codes on our website, using our data browser.
base<-"https://www.quandl.com/api/v3/datasets/"
dataname<-"WIKI/FB/data.csv?"
key <-"api_key=u7mzU7dPxbrAm3_c3LEb"
url <- paste(base,dataname,key, sep="")
# If we are reading a .csv file, it could not be any easier so long as the .csv file follows the minimum standard.
# That is, there is a header row and it is the first row.
FB_prices_from_CSV<-read.csv(url)
# what if instead your data are not csv, but JSON as most are?
# We are going to fetch the same data, but using JSON instead.
dataname<-"WIKI/FB/data.csv?"
url <- paste(base,dataname,key, sep="")
m2<-fromJSON(url)
# This script describes gathering data from an API
# We will need three packages: httr, jsonlite, lubrdidate
# to ease the code I use easypackages
library(easypackages)
mypackages<-c("httr", "jsonlite", "lubridate")
packages(mypackages)
libraries(mypackages)
options(stringsAsFactors = FALSE)
# First let's access an open API
# Quandl Key u7mzU7dPxbrAm3_c3LEb
# Typical api format https://www.quandl.com/api/v3/datasets/WIKI/FB/data.csv?api_key=YOURAPIKEYHERE
#Quandl Codes
#To download a dataset, you will need to know its “Quandl code”.  In the above example, you downloaded a dataset with the Quandl code “WIKI/FB”.
#Every Quandl code has 2 parts: the database code (“WIKI”) which specifies where the data comes from, and the dataset code (“FB”) which identifies the specific time series you want.
#You can find Quandl codes on our website, using our data browser.
base<-"https://www.quandl.com/api/v3/datasets/"
dataname<-"WIKI/FB/data.csv?"
key <-"api_key=u7mzU7dPxbrAm3_c3LEb"
url <- paste(base,dataname,key, sep="")
# If we are reading a .csv file, it could not be any easier so long as the .csv file follows the minimum standard.
# That is, there is a header row and it is the first row.
FB_prices_from_CSV<-read.csv(url)
# what if instead your data are not csv, but JSON as most are?
# We are going to fetch the same data, but using JSON instead.
dataname<-"WIKI/FB/data.json?"
url <- paste(base,dataname,key, sep="")
m2<-fromJSON(url)
View(m2)
m2$dataset_data$data
header(m2$dataset_data$data)
head(m2$dataset_data$data)
names(m2)
names(m2$dataset_data)
FB_prices_from_JSON<-m2$dataset_data$data
names(FB_prices_from_JSON)<-m2$dataset_data$column_names
FB_prices_from_JSON<-data.frame(m2$dataset_data$data)
names(FB_prices_from_JSON)<-m2$dataset_data$column_names
View(FB_prices_from_CSV)
dataname<-"WIKI/FB/data.json?column_index=4"
url <- paste(base,dataname,key, sep="")
m2<-fromJSON(url)
FB_prices_from_JSON_closing<-data.frame(m2$dataset_data$data)
names(FB_prices_from_JSON_closing)<-m2$dataset_data$column_names
install.packages("Quandl")
library(Quandl)
Quandl.api_key(key)
data<-Quandl("WIKI/FB")
# This script describes gathering data from an API
# We will need three packages: httr, jsonlite, lubrdidate
# to ease the code I use easypackages
library(easypackages)
mypackages<-c("httr", "jsonlite", "lubridate")
packages(mypackages)
libraries(mypackages)
options(stringsAsFactors = FALSE)
# First let's access an open API
# Quandl Key u7mzU7dPxbrAm3_c3LEb
# Typical api format https://www.quandl.com/api/v3/datasets/WIKI/FB/data.csv?api_key=YOURAPIKEYHERE
#Quandl Codes
#To download a dataset, you will need to know its “Quandl code”.  In the above example, you downloaded a dataset with the Quandl code “WIKI/FB”.
#Every Quandl code has 2 parts: the database code (“WIKI”) which specifies where the data comes from, and the dataset code (“FB”) which identifies the specific time series you want.
#You can find Quandl codes on our website, using our data browser.
base<-"https://www.quandl.com/api/v3/datasets/"
dataname<-"WIKI/FB/data.csv?"
key <-"u7mzU7dPxbrAm3_c3LEb"
url <- paste(base,dataname,"api_key=",key, sep="")
# If we are reading a .csv file, it could not be any easier so long as the .csv file follows the minimum standard.
# That is, there is a header row and it is the first row.
FB_prices_from_CSV<-read.csv(url)
# what if instead your data are not csv, but JSON as most are?
# We are going to fetch the same data, but using JSON instead.
dataname<-"WIKI/FB/data.json?"
url <- paste(base,dataname,"api_key=",key, sep="")
m2<-fromJSON(url)
FB_prices_from_JSON<-data.frame(m2$dataset_data$data)
names(FB_prices_from_JSON)<-m2$dataset_data$column_names
# What if you only wanted to fetch closing prices? We can see this is column 4 in our dataset.
# We can retrieve individual columns along with the date column by simply adding a category in between the dataset name and the key.
# Here we indicate we want the fourth column.
dataname<-"WIKI/FB/data.json?column_index=4"
url <- paste(base,dataname,"api_key=",key, sep="")
m2<-fromJSON(url)
FB_prices_from_JSON_closing<-data.frame(m2$dataset_data$data)
names(FB_prices_from_JSON_closing)<-m2$dataset_data$column_names
# Finally, some api's already have dedicated R packages. Quandl is one of them.
install.packages("Quandl")
library(Quandl)
Quandl.api_key(key)
data<-Quandl("WIKI/FB")
install.packages("Quandl")
View(data)
install.packages(c("httr", "rscorecard"))
install.packages(c("swirl", "swirlify"))
library(swirlify)
setwd("~/GitHub")
new_lesson("Intro to Data Science", "UL Intro to R")
cars$type
view(cars)
View(cars)
View(car)
View(cars)
plot(0,xlim=c(-10,10),ylim=c(-10,10),type="n",xlab="",ylab="",bty="n",xaxt="n",yaxt="n", main="Population vs. Sample")
draw.circle(0,0,7,border="black",col="yellow")
draw.circle(3,0,3,border="black",col="red")
text(-3.5,0,"Population", font=2)
text(3,0,"Sample", font=2)
install.packages("openintro")
install.packages("plotrix")
library(plotrix)
plot(0,xlim=c(-10,10),ylim=c(-10,10),type="n",xlab="",ylab="",bty="n",xaxt="n",yaxt="n", main="Population vs. Sample")
draw.circle(0,0,7,border="black",col="yellow")
draw.circle(3,0,3,border="black",col="red")
text(-3.5,0,"Population", font=2)
text(3,0,"Sample", font=2)
demo_lesson()
demo_lesson()
demo_lesson()
swirl()
library(swirl)
ls()
swirl()
